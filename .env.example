# Azure Architect Assistant - Environment Configuration
# Copy this file to .env and configure with your values

# ===========================
# OpenAI Configuration
# ===========================
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ===========================
# Server Configuration
# ===========================
BACKEND_PORT=8000
FRONTEND_PORT=5173
BACKEND_URL=http://localhost:8000

# ===========================
# Database Configuration
# ===========================
PROJECTS_DATABASE=data/projects.db
INGESTION_DATABASE=data/ingestion.db
DIAGRAMS_DATABASE=data/diagrams.db

# ===========================
# Storage Configuration
# ===========================
KNOWLEDGE_BASES_ROOT=data/knowledge_bases

# ===========================
# UI Configuration
# ===========================
# Optional: Display a banner at the top to distinguish worktrees/environments
# VITE_BANNER_MESSAGE=ðŸ”§ DEVELOPMENT WORKTREE - branch-name

# ===========================
# Agent Configuration
# ===========================
# LangGraph Migration (Phase 3+)
# Set to true to use LangGraph-based agent orchestration instead of legacy LangChain
# AAA_USE_LANGGRAPH=false

# Phase 5: Enable explicit stage routing and retry semantics
# AAA_ENABLE_STAGE_ROUTING=false

# Phase 6: Enable multi-agent specialists (ADR, Validation, Pricing, IaC)
# AAA_ENABLE_MULTI_AGENT=false

# ===========================
# LLM Analysis / JSON Repair
# ===========================
# Max completion tokens used for document analysis extraction
# LLM_ANALYZE_MAX_TOKENS=6000

# Minimum tokens reserved for JSON repair retries
# LLM_JSON_REPAIR_MIN_TOKENS=1500

# Repair budget divisor from initial max tokens
# LLM_JSON_REPAIR_TOKEN_DIVISOR=2

# Truncated response log lengths for preview/error diagnostics
# LLM_RESPONSE_PREVIEW_LOG_CHARS=500
# LLM_RESPONSE_ERROR_LOG_CHARS=1000

